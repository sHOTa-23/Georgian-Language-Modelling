{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c68ecb-d83a-45de-8704-3d468a3a8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install datasets\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d99cedc-921a-4cf7-8b60-ab2e05a5c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07a279a-8650-477b-b382-604472f8d56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d12b36c1fa84e70a86038a69aa07923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e778da0c84947b084a5bddc525d4a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/359k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset oscar/unshuffled_original_ka (download: 649.20 MiB, generated: 3.51 GiB, post-processed: Unknown size, total: 4.14 GiB) to /home/jupyter/.cache/huggingface/datasets/oscar/unshuffled_original_ka/1.0.0/84838bd49d2295f62008383b05620571535451d84545037bb94d6f3501651df2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d079e3d2d74ff59c8af617a4c32bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/164 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e4759b47054b979e625ff6ccbca4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c29bac6fa04eab8c2514e09c9bb61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/352M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214f76c694774ecb93fa70c7856a9cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/563916 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset oscar downloaded and prepared to /home/jupyter/.cache/huggingface/datasets/oscar/unshuffled_original_ka/1.0.0/84838bd49d2295f62008383b05620571535451d84545037bb94d6f3501651df2. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "georgian_oscar = load_dataset(\"oscar\", \"unshuffled_original_ka\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc1b017-a6ef-4ca1-90b9-3d58e6814d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = georgian_oscar['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bdf5818-e315-4c1f-92c5-d05eb63c68f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cab3ac77-5e61-44ce-b337-eebcacf747b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11511987"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "all_sentences = []\n",
    "for txt in sents:\n",
    "    txt = txt.split('\\n')\n",
    "    tokenized_text = []\n",
    "    for sentence in txt:\n",
    "        tokenized_text += sent_tokenize(sentence)\n",
    "    all_sentences += tokenized_text\n",
    "len(all_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8d4c301-f5e0-4c11-a304-2c8ac13a3afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = '[^ ]*[^აბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰ0123456789 ]+[^ ]*'\n",
    "new_sentences = []\n",
    "def clean(x):\n",
    "    x = re.sub('#\\S+', '', x)  # remove hashtags\n",
    "    x = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>@[\\]^_`{|}~\"\"\"), ' ', x)  # remove punctuations\n",
    "    x = re.sub('\\s+', ' ', x) # remove extra spaces\n",
    "    x = re.sub(pattern, \"\", x) # remove non only georgian letters\n",
    "    return x\n",
    "for i in range(len(all_sentences)): \n",
    "    if i % 1000000 == 0:\n",
    "        print(i)\n",
    "    new_sentences.append(clean(all_sentences[i]))\n",
    "all_sentences = new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7049c602-3652-4365-9cf8-6d796e51c1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n"
     ]
    }
   ],
   "source": [
    "long_word_pattern = '[^ ]{26,9999}'\n",
    "j = 0\n",
    "for i in range(len(all_sentences)):\n",
    "    if i % 1000000 == 0 :\n",
    "        print(i)\n",
    "    pre = all_sentences[i]\n",
    "    all_sentences[i] = re.sub(long_word_pattern,\"\",all_sentences[i])\n",
    "    if pre != all_sentences[i]:\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6de0c6ce-f23a-4a45-bda8-ef3432800202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11511987\n",
      "9961319\n"
     ]
    }
   ],
   "source": [
    "def filter_func(x):\n",
    "    l = len(x.split())\n",
    "    return l >=5 and l <=500\n",
    "print(len(all_sentences))\n",
    "all_sentences = list(filter(filter_func,all_sentences))\n",
    "print(len(all_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e55612c-4e8b-48ee-9e77-75a7b343737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"Sentence\": all_sentences})\n",
    "df.to_csv(\"filtered_sentences.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88baac66-2ab9-4628-aab1-4d767891ec49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = open('medium.txt','w')\n",
    "for sent in all_sentences[:200_000]:\n",
    "    sent = sent.replace('\\n','')\n",
    "    fl.write(sent)\n",
    "    fl.write('\\n')\n",
    "fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89a03020-e2a7-48a9-8421-81ee9900ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from argparse import Namespace\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertForMaskedLM,\n",
    "    BertTokenizer,\n",
    "    AdamW,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "args = Namespace()\n",
    "args.train = \"medium.txt\"\n",
    "args.max_len = 128\n",
    "args.epochs = 1\n",
    "args.batch_size = 4\n",
    "args.token_path = 'georgian-vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77e9a00a-bf76-4c31-bbd3-4c9884ff10bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./georgian-vocab.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "# initialize\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    clean_text=True,\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=False,\n",
    "    lowercase=False\n",
    ")\n",
    "# and train\n",
    "tokenizer.train(files=args.train, vocab_size=30_000, min_frequency=2,\n",
    "                limit_alphabet=1000, wordpieces_prefix='##',\n",
    "                special_tokens=[\n",
    "                    '[PAD', '[UNK]', '[CLS]', '[SEP]', '[MASK]'])\n",
    "\n",
    "# Save files to disk\n",
    "tokenizer.save_model(\".\", \"georgian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56672d29-f81e-4eb8-920a-c27d2ec6becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tok = BertTokenizer(\n",
    "    args.token_path\n",
    ")\n",
    "# and trai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d8e7b84-1289-46c6-98d1-5bc3343dc629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 25401, 289, 2306, 9937, 13489, 155, 12375, 927, 11255, 1393, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok('გამარჯობა როგორ ხარ მებადური ზღვაშიშევარდნილი')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "953d1f13-0fb2-4f83-a3fa-76219b9c4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLMDataset(Dataset):\n",
    "    def __init__(self, file, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.lines = self.load_lines(file)\n",
    "        self.ids = self.encode_lines(self.lines)\n",
    "        \n",
    "    def load_lines(self, file):\n",
    "        with open(file) as f:\n",
    "            lines = [\n",
    "                line\n",
    "                for line in f.read().splitlines()\n",
    "                if (len(line) > 0 and not line.isspace())\n",
    "            ]\n",
    "        return lines\n",
    "    \n",
    "    def encode_lines(self, lines):\n",
    "        batch_encoding = self.tokenizer(\n",
    "            lines, add_special_tokens=True, truncation=True, max_length=args.max_len\n",
    "        )\n",
    "        return batch_encoding[\"input_ids\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.ids[idx], dtype=torch.long)\n",
    "        \n",
    "train_dataset = MaskedLMDataset(args.train, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c45f062-8ea4-4ad4-bdbc-6cea5361657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tok, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33a5520b-9d91-428e-b50f-4bd627c91146",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig(vocab_size=30_000,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=6,\n",
    "    num_hidden_layers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c78e6080-b65c-4cf0-ba79-f12743704d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "bert = BertForMaskedLM(config).to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cafead54-ac36-474c-ac56-1f8b34eabc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66587184"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size = sum(t.numel() for t in bert.parameters())\n",
    "model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ee3dd5b-a540-45b9-a6e5-4d468af68571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"model\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=64,\n",
    "    save_steps=5000,  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9253d8f3-40bd-4cfc-b807-85d996de1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3df6c94d-c02d-4843-952f-04482fe243da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 200000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 62500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62500' max='62500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62500/62500 3:29:28, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>9.255800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.784100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>8.530700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>8.369900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>8.235600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>8.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>7.914300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>7.796500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>7.687700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>7.574700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>7.446500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>7.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>7.167400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>7.058500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>6.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>6.860900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>6.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>6.625200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>6.560600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>6.452200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>6.363100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>6.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>6.235800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>6.165200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>6.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>6.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>5.955900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>5.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>5.905900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>5.829800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>5.797900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>5.708400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>5.640700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>5.631400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>5.631500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>5.516900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>5.508700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>5.459200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>5.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>5.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>5.347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>5.310200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>5.265100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>5.280200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>5.221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>5.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>5.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>5.172300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>5.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>5.085700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>5.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>5.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>4.963300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>4.993200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>4.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>4.939100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>4.892700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>4.900600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>4.857100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>4.850500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>4.808900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>4.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>4.760100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>4.712900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>4.691300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>4.707100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>4.721300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>4.674500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>4.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>4.643400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>4.599900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>4.587700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>4.584800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>4.551100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>4.568600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>4.504400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>4.520700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>4.474300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>4.505500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>4.476100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>4.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>4.427700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>4.417300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>4.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>4.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>4.385800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>4.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>4.340400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>4.336100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>4.320100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>4.335900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>4.283700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>4.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>4.303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>4.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>4.260900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>4.272600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>4.234300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49500</td>\n",
       "      <td>4.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>4.254600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50500</td>\n",
       "      <td>4.233300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>4.249500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51500</td>\n",
       "      <td>4.213400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>4.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>4.174200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>4.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53500</td>\n",
       "      <td>4.172500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>4.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54500</td>\n",
       "      <td>4.139600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>4.162800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55500</td>\n",
       "      <td>4.155900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>4.182900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56500</td>\n",
       "      <td>4.142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>4.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>4.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>4.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58500</td>\n",
       "      <td>4.130300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>4.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59500</td>\n",
       "      <td>4.112900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>4.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60500</td>\n",
       "      <td>4.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>4.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61500</td>\n",
       "      <td>4.114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>4.104200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>4.137500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to model/checkpoint-5000\n",
      "Configuration saved in model/checkpoint-5000/config.json\n",
      "Model weights saved in model/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to model/checkpoint-10000\n",
      "Configuration saved in model/checkpoint-10000/config.json\n",
      "Model weights saved in model/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to model/checkpoint-15000\n",
      "Configuration saved in model/checkpoint-15000/config.json\n",
      "Model weights saved in model/checkpoint-15000/pytorch_model.bin\n",
      "Saving model checkpoint to model/checkpoint-25000\n",
      "Configuration saved in model/checkpoint-25000/config.json\n",
      "Model weights saved in model/checkpoint-25000/pytorch_model.bin\n",
      "Saving model checkpoint to model/checkpoint-30000\n",
      "Configuration saved in model/checkpoint-30000/config.json\n",
      "Model weights saved in model/checkpoint-30000/pytorch_model.bin\n",
      "Saving model checkpoint to model/checkpoint-35000\n",
      "Configuration saved in model/checkpoint-35000/config.json\n",
      "Model weights saved in model/checkpoint-35000/pytorch_model.bin\n",
      "Saving model checkpoint to model/checkpoint-40000\n",
      "Configuration saved in model/checkpoint-40000/config.json\n",
      "Model weights saved in model/checkpoint-40000/pytorch_model.bin\n",
      "Saving model checkpoint to model/checkpoint-45000\n",
      "Configuration saved in model/checkpoint-45000/config.json\n",
      "Model weights saved in model/checkpoint-45000/pytorch_model.bin\n",
      "Saving model checkpoint to model/checkpoint-50000\n",
      "Configuration saved in model/checkpoint-50000/config.json\n",
      "Model weights saved in model/checkpoint-50000/pytorch_model.bin\n",
      "Saving model checkpoint to model/checkpoint-55000\n",
      "Configuration saved in model/checkpoint-55000/config.json\n",
      "Model weights saved in model/checkpoint-55000/pytorch_model.bin\n",
      "Saving model checkpoint to model/checkpoint-60000\n",
      "Configuration saved in model/checkpoint-60000/config.json\n",
      "Model weights saved in model/checkpoint-60000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=62500, training_loss=5.21979865234375, metrics={'train_runtime': 12568.6493, 'train_samples_per_second': 318.252, 'train_steps_per_second': 4.973, 'total_flos': 8.535342229812634e+16, 'train_loss': 5.21979865234375, 'epoch': 20.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d36c509-d0cf-44d7-ae4a-5671af282bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in last_model/config.json\n",
      "Model weights saved in last_model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "bert.save_pretrained(\"last_model\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8244f376ee9b986434839952ed3b114cab921731cb545ad25d93cb1a288db67f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
